---
title: "Final Project"
author: "Minoo Ahmadi"
date: "January 19, 2017"
output: html_document
---
Power analysis
A bunch of regressions and plotting.

```{r "setup", include=FALSE}
require("knitr")
opts_knit$set(root.dir = "~/gits/project/")
```


```{r}
library (haven)
getwd() 
setwd("C:/Users/ahmadi/Documents/Courses/PSYC798W/PSYC798W_R_Winter_2017/Data")

my.data<- read_sav("Data_FYP.sav")
variable.names(my.data)
my.data1<- my.data

my.data1 <- gather(my.data1, social.anxiety.scale, social.anxiety.score, 202:204) # gathering BFNE, SPS, and SIAS under social.anxiety, as they are all indicators of social anxiety.
my.data1$social.anxiety.scale <- as.factor(my.data1$social.anxiety.scale)

# reg1<- glm(DominanceCongruencyEffect200~social.anxiety.score, data = my.data1)
#summary.lm(reg1)
#ggplot(my.data1, aes(social.anxiety.score, DominanceCongruencyEffect200)) + geom_point(aes(color = social.anxiety.scale), size = 4)+ geom_smooth(method = "lm")+ scale_color_brewer(palette = "Set1")

#reg2<- glm(DominanceCongruencyEffect200~score + BIS + IPIP_Domineering, data = my.data)
#summary.lm(reg2)
#ggplot(my.data, aes(score, DominanceCongruencyEffect200)) + geom_point()+ geom_smooth(method = "lm")
#ggplot(my.data, aes(BIS, DominanceCongruencyEffect200)) + geom_point()+ geom_smooth(method = "lm")
#ggplot(my.data, aes(IPIP_Domineering, DominanceCongruencyEffect200)) + geom_point()+ geom_smooth(method = "lm")

my.data1 <- gather(my.data1, soa, dom.cong.eff, 48:50) # gathering DominanceEffect200, DominanceEffect400, and DominanceEffect800 under SOA with 3 lelvels (200, 400, 800), and having their scores under dom.cong.eff.

#reg3<- glm(dom.cong.eff~social.anxiety.score, data = my.data1)
#summary.lm(reg3)
#ggplot(my.data1, aes(social.anxiety.score, dom.cong.eff)) + geom_point(aes(color = social.anxiety.scale), size = 2)+ geom_smooth(method = "lm")+ scale_color_brewer(palette = "Set1")+ facet_grid(.~soa)

reg4<- glm(dom.cong.eff~social.anxiety.score+ BIS + IPIP_Domineering, data = my.data1)
summary.lm(reg4)

ggplot(my.data1, aes(social.anxiety.score, dom.cong.eff)) + geom_point(aes(color = social.anxiety.scale), size = 2)+ geom_smooth(method = "lm")+ scale_color_brewer(palette = "Set1")+ facet_grid(.~soa)

ggplot(my.data1, aes(BIS, dom.cong.eff)) + geom_point(size = 2)+ geom_smooth(method = "lm")+ facet_grid(.~soa)

reg5<- glm(dom.cong.eff~social.anxiety.score+ BIS + IPIP_Domineering, data = my.data1, subset = soa=="DominanceCongruencyEffect200")
summary.lm(reg5)
reg6<- glm(dom.cong.eff~social.anxiety.score+ BIS + IPIP_Domineering, data = my.data1, subset = soa=="DominanceCongruencyEffect400")
summary.lm(reg6)
reg7<- glm(dom.cong.eff~social.anxiety.score+ BIS + IPIP_Domineering, data = my.data1, subset = soa=="DominanceCongruencyEffect800")
summary.lm(reg7)

```
Based on the analysis above, we can conclude that while the overal cueing effect for dominant faces (Dominance Congruency Effect) is only predicted by BIS score, when we break it to its SOA subcomponents we that the social anxiety score (BFNE+SPS+SIAS) predicts it at SOA of 200ms and a BIS is the best predictor at SOA of 800ms.




## Power analysis for a regression analysis
Regress Dominance congruence effect on social anxiety scores (SPS, SIAS, BFNE) and domoinance level (IPIP_Domineering. 

``` {r}

pwr.f2.test(u = 2, v= NULL, f2 = .15, sig.level = .05, power = .8) # returns v = 64.31932 => N= 67



df.denom <- 23 # 27 (my sample size) - 3 (predictors) - 1 
eff.size <- .15 # medium effect size
p.val <- .05
pow # post-hoc power analysis
pwr.f2.test(2, v = df.denom, f2 = eff.size, sig.level = p.val, power = NULL) # returns power = 0.3617643


eff.size <- .35 # large effect size
p.val <- .05
pow # post-hoc power analysis
pwr.f2.test(3, 23, .35,.05, power = NULL) # returns power = 0.6526652

df.num <- 3 # number of continuous variables (predictors)
eff.size <- .35 # large effect size
p.val <- .05
pow <- .8
pwr.f2.test(3, v= NULL, .35, .05, power = .8) # returns v = 31.3129 => N = 35


```

First, simulating data for a logistic regression:

```{r}
set.seed(1)

repetitions = 1000
N = 10000
n = N/8
var1  = c(   .03,    .03,    .03,    .03,    .06,    .06,    .09,   .09)
var2  = c(     0,      0,      0,      1,      0,      1,      0,     1)
rates = c(0.0025, 0.0025, 0.0025, 0.00395, 0.003, 0.0042, 0.0035, 0.002)

var1    = rep(var1, times=n)
var2    = rep(var2, times=n)
var12   = var1**2
var1x2  = var1 *var2
var12x2 = var12*var2

significant = matrix(nrow=repetitions, ncol=7)

for(i in 1:repetitions){
  responses<- rbinom(n=N, size=1, prob=rates)
  model<- glm(responses~var1+var2+var12+var1x2+var12x2, family=binomial(link="logit"))
  significant[i,1:5]<- (summary(model)$coefficients[2:6,4]<.05)
  significant[i,6]<- sum(significant[i,1:5])
  modelDev<- model$null.deviance-model$deviance
  significant[i,7]<- (1-pchisq(modelDev, 5))<.05
}



```

The example for t.test:
```{r}
n.sim <- 10000
sample.n <- 100
mean.difference <- .3
sd.x <- 1
sd.y <- 1

results <- data.frame(iteration = 1:n.sim, p.ttest = NA, p.wilcox = NA)

for(counter in 1:n.sim) {
  this.x <- rnorm(sample.n, mean = 0, sd = sd.x)
  this.y <- rnorm(sample.n, mean = mean.difference, sd = sd.y)
  this.ttest <- t.test(this.x, this.y)
  this.wilcox <- wilcox.test(this.x, this.y)
  results[counter, "p.ttest"] <- this.ttest$p.value
  results[counter, "p.wilcox"] <- this.wilcox$p.value
  if(counter %% 500 == 0) {
    print(paste("finished simulation #", counter))
  }
}
head(results)
results$ttestsig <- ifelse(results$p.ttest < .05, TRUE, FALSE)
results$wilcoxsig <- ifelse(results$p.wilcox < .05, TRUE, FALSE)
head(results)
sum(results$ttestsig)/nrow(results)
sum(results$wilcoxsig)/nrow(results)


```



The example for correlation:

``` {r}
# set up the parameters of the simulation
n.sim <- 10000
sample.ns <- 100:200
correlation <- .2

power.analysis.results <- data.frame(sample.size = sample.ns, power = NA)

#for(this.sample in sample.ns) {
  cortable <- matrix(c(1, correlation, correlation, 1), ncol = 2)
  # "pre-allocate" the results table
  results <- data.frame(iteration = 1:n.sim, p = NA)
  
  for(counter in 1:n.sim) {
    this.data <- as.data.frame(mvrnorm(this.sample, mu = c(0, 0), Sigma = cortable))
    this.cortest <- cor.test(this.data$V1, this.data$V2)
    results[counter, "p"] <- this.cortest$p.value
    if(counter %% 500 == 0) {
      print(paste("finished simulation #", counter))
    }
  }
  #head(results)
  results$sig <- ifelse(results$p < .05, TRUE, FALSE)
  #head(results)
  power.analysis.results[power.analysis.results$sample.size == this.sample, "power"] <-   sum(results$sig)/nrow(results)

}

head(power.analysis.results)

power.threshold <- .9

min.sample <- min(power.analysis.results$sample.size[power.analysis.results$power >= power.threshold])
ggplot(power.analysis.results, aes(sample.size, power)) + geom_line() + 
  geom_smooth(se = FALSE, method = "loess") + 
  geom_hline(yintercept = max(power.analysis.results$power), color = "red") +
  annotate("text", x = min(power.analysis.results$sample.size) + (max(power.analysis.results$sample.size) - min(power.analysis.results$sample.size))/2, y = 1.02, label = paste("max power in these simulations:", max(power.analysis.results$power))) +
  geom_hline(yintercept = power.threshold, color = "red", linetype = 2) + 
  annotate("text", x = min(power.analysis.results$sample.size) + (max(power.analysis.results$sample.size) - min(power.analysis.results$sample.size))/2, y = power.threshold + .02, label = paste("sample needed for", power.threshold, " power:", min.sample))
    

```













## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Dominance Congruency effect (200, 400, 800): gather. 3 levels.

power = sig tests/totall tests
effect size for multiple regression: f^2 = R^2/1-R^2 (sort of an odds ratio)

Regress Dominance congruence effect on social anxiety scores (SPS, SIAS, BFNE), dominance level (IPIP_Domineering). f^2 =  .207/1-.207 = .261

install.packages("pwr")
library(pwr)
pwr.f2.test (1,25, .261, .05, power = NULL)

     Multiple regression power calculation 

              u = 1
              v = 25
             f2 = 0.261
      sig.level = 0.05
          power = 0.7229382


Means:
BFN: 22
SPS: 31
SIAS: 42




pwr.f2.test (1,25, f2= NULL, .05, .8)

     Multiple regression power calculation 

              u = 1
              v = 25
             f2 = 0.3147446
      sig.level = 0.05
          power = 0.8
          

Function: pwr.f2.test 
Arguments: 
u: Numerator degrees of freedom (the number of continuous predictors plus the number of dummy variables minus one) 
v: Denominator (error) degrees of freedom  
f2: Effect Size (Cohen suggests f2 values of 0.02, 0.15, and 0.35 represent small, medium, and large effect sizes). 
sig.level: Significance level power: Power of test

pwr.f2.test(u = 3, v = NULL, f2 = .15, sig.level = 0.05, power = 0.8)

     Multiple regression power calculation 

              u = 3
              v = 72.70585
             f2 = 0.15
      sig.level = 0.05
          power = 0.8
          
==> 73+3+1=77 is the require sample size for getting a power of .8 with 3 continuous variables.

